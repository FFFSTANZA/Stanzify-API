# Multi-AI Orchestration - Example Usage

## Quick Start

1. Open `index.html` in your browser
2. You'll see the **Multi-AI Orchestration** interface with:
   - Prompt input area
   - "ğŸ­ Orchestrate AIs" button
   - Orchestration info panel
   - Conversation history
   - File workspace

## Example Workflow

### Example 1: Refactoring Code

**Your Input:**
```
Refactor the modal component to improve code readability and maintainability
```

**What Happens:**
1. **Task Classification** analyzes the prompt
   - Detects keywords: "refactor", "improve", "readability", "maintainability"
   - Primary task: `refactor`
   - Confidence score: 4 (4 matching keywords)

2. **Smart Routing** selects optimal AIs:
   ```
   Selected AIs: DeepSeek, Qwen, Qwen-backup, Mistral, GPT-4o
   ```
   - DeepSeek: Refactor specialist (score: 3.5)
   - Qwen: Refactor specialist (score: 3.5)
   - Qwen-backup: Refactor specialist (score: 3.0)
   - Mistral: Optimize specialist (score: 1.5)
   - GPT-4o: General purpose (score: 0.5)

3. **Parallel Execution** sends prompt to all 5 AIs simultaneously
   - Each AI processes independently
   - Responses collected as they arrive
   - Total time: ~1-2 seconds (mock) / 30-60 seconds (real)

4. **Response Merging** combines results:
   ```
   Strategy: Balanced
   - Expert opinion: DeepSeek (refactor specialist)
   - Democratic consensus: What most AIs agree on
   - Agreement level: HIGH (multiple AIs suggest similar approaches)
   ```

5. **Output Display:**
   - **System Message**: "Task Classification: refactor | Routing to: DeepSeek, Qwen..."
   - **Merged Response**: Combined best practices from all AIs
   - **Individual Responses**: Each AI's unique perspective
   - **Completion Message**: "âœ… Orchestration complete! 5 AIs responded"

### Example 2: Debugging an Error

**Your Input:**
```
Debug why the submit button throws an error when clicked
```

**Orchestration Process:**

```
Task Classification:
- Primary: debug
- Keywords found: ["debug", "error"]

Smart Routing:
- Llama (debug specialist) - Score: 3.5
- GPT-4o (general + debug) - Score: 3.5
- DeepSeek (debug capable) - Score: 2.0
- GPT-4o-backup (general) - Score: 1.5
- You.com (code + debug) - Score: 2.0

Parallel Execution:
âœ“ Llama: "As a debugging specialist, I would check event listeners..."
âœ“ GPT-4o: "The error likely comes from missing null checks..."
âœ“ DeepSeek: "I'd optimize the error handling while fixing..."
âœ“ GPT-4o-backup: "Try wrapping the click handler in try-catch..."
âœ“ You.com: "Search shows this is a common DOM timing issue..."

Response Merging (Expert Strategy):
Expert Selected: Llama (debug specialist)
Confidence Score: 8.73
Final Output: Llama's response + supporting insights from others
```

### Example 3: Creating New Feature

**Your Input:**
```
Create a new dark mode toggle component with smooth transitions
```

**Orchestration Flow:**

```
ğŸ“Š Classification:
   Task: create
   Secondary: architecture (detected "component")

ğŸ¯ Routing Decision:
   Primary picks: GPT-4o, Gemini, You.com
   Secondary picks: Qwen, DeepSeek
   Final: GPT-4o, Gemini, You.com, Qwen, DeepSeek

âš¡ Parallel Execution Results:
   â€¢ GPT-4o (0.95s): Comprehensive implementation with hooks
   â€¢ Gemini (1.15s): Clean architecture with state management
   â€¢ You.com (0.82s): Modern solution with CSS variables
   â€¢ Qwen (1.02s): Well-structured component design
   â€¢ DeepSeek (0.88s): Optimized performance approach

ğŸ”€ Merging (Balanced Strategy):
   Common Elements:
   âœ“ All suggest useState for theme state
   âœ“ 4/5 recommend localStorage persistence
   âœ“ 3/5 include CSS transition properties
   âœ“ All use CSS variables for theming
   
   Expert Pick: Gemini (architecture specialist)
   Democratic Consensus: HIGH agreement
   
   Final Output: 
   - Gemini's architecture as base
   - GPT-4o's implementation details
   - You.com's modern CSS approach
   - Performance tips from DeepSeek
```

## Merge Strategies Explained

### 1. Balanced Strategy (Default)
Combines expert opinion with democratic voting:

```javascript
// Pseudocode
balanced = {
  baseArchitecture: expertAI.response,
  implementation: democraticConsensus.commonPatterns,
  edgeCases: uniqueInsights.fromAllAIs
}
```

**Use When:** You want comprehensive coverage with specialist insight

### 2. Democratic Strategy
Majority rules - uses what most AIs agree on:

```javascript
// Pseudocode
democratic = {
  content: mostFrequentPatterns,
  confidence: agreementPercentage,
  dissent: uniqueSuggestions
}
```

**Use When:** You want the most common, battle-tested approach

### 3. Expert Strategy
Trusts the specialist AI for the task:

```javascript
// Pseudocode
expert = {
  primary: specialistAI.response,
  weight: expertiseScore * contentQuality,
  supporting: otherAIs.relevant.points
}
```

**Use When:** You trust specialist knowledge over consensus

## Command Palette Examples

### Toggle Orchestration
```
âŒ˜K â†’ "Toggle Multi-AI"

Before: ğŸ­ Orchestrate AIs (5-10 AIs in parallel)
After:  Send to GPT-4o mini (Single AI mode)
```

### Change Merge Strategy
```
âŒ˜K â†’ "Merge Strategy"

Cycle: balanced â†’ democratic â†’ expert â†’ balanced

Each shows description:
- Balanced: "Combines expert opinion with democratic consensus"
- Democratic: "Uses majority voting - what most AIs agree on"
- Expert: "Trusts the specialist AI most suited for the task"
```

### View AI Pool
```
âŒ˜K â†’ "View AI Pool Status"

Output:
AI Pool Manager
10 workers ready:

â€¢ GPT-4o (general)
â€¢ GPT-4o-backup (general)
â€¢ DeepSeek (optimize)
â€¢ Qwen (refactor)
â€¢ Qwen-backup (refactor)
â€¢ Gemini (architecture)
â€¢ Mistral (optimize)
â€¢ Llama (debug)
â€¢ Perplexity (general)
â€¢ You.com (create)
```

## Conversation Panel Anatomy

After orchestration, you'll see:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ You                    3:45:23 PM        â”‚
â”‚ Refactor the modal component...         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ System                 3:45:23 PM        â”‚
â”‚ ğŸ¯ Task Classification: refactor        â”‚
â”‚ ğŸ¤– Routing to: DeepSeek, Qwen, Mistral..â”‚
â”‚ âš¡ Executing in parallel...             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ­ Merged (5 AIs Â· balanced) 3:45:25 PM â”‚
â”‚ MERGED RESPONSE (Balanced Approach)     â”‚
â”‚                                          â”‚
â”‚ Combining democratic consensus with...  â”‚
â”‚ [Full merged response content]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ System                 3:45:25 PM        â”‚
â”‚ âœ… Orchestration complete! 5 AIs...    â”‚
â”‚ ğŸ“Š View individual responses below      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DeepSeek (optimize)    3:45:24 PM       â”‚
â”‚ [DeepSeek's individual response]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Qwen (refactor)        3:45:24 PM       â”‚
â”‚ [Qwen's individual response]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

... (3 more individual responses)
```

## Real-World Scenarios

### Scenario 1: Large Refactoring
You need to refactor a complex component. Orchestration helps by:
- Getting multiple architectural perspectives
- Seeing different refactoring patterns
- Identifying common best practices
- Spotting edge cases one AI might miss

### Scenario 2: Tricky Bug
A subtle bug that's hard to diagnose. Benefits:
- Multiple debugging approaches
- Different angle on the problem
- Higher chance of finding root cause
- Validation of solution across specialists

### Scenario 3: New Feature Design
Building something from scratch. Advantages:
- Various implementation strategies
- Different architecture patterns
- Performance considerations from specialists
- Consensus on best practices

## Tips for Best Results

1. **Be Specific in Prompts**
   - âŒ "Fix this"
   - âœ… "Debug why the form validation fails on submit"

2. **Include Task Keywords**
   - Use words like: refactor, debug, create, optimize, explain
   - Helps classification accuracy

3. **Choose Right Strategy**
   - Complex problems â†’ Balanced
   - Standard patterns â†’ Democratic
   - Specialized tasks â†’ Expert

4. **Review Individual Responses**
   - Don't just read merged result
   - Check individual insights
   - Look for unique approaches

5. **Experiment with Context**
   - Add relevant files to context
   - Helps AIs understand codebase
   - Improves response quality

## Performance Expectations

### Mock Mode (Current):
- Classification: <10ms
- Routing: <5ms
- Parallel execution: 1-2 seconds
- Merging: 10-50ms
- Total: ~2 seconds

### Real AI Mode (Future):
- Classification: <10ms
- Routing: <5ms
- Parallel execution: 30-60 seconds (API calls)
- Merging: 50-100ms
- Total: ~30-60 seconds

## Troubleshooting

### No AIs Selected
- Check if orchestration is enabled
- Verify prompt has recognizable keywords
- Try more specific task description

### Merging Fails
- Ensure at least 2 responses received
- Check console for errors
- Try different merge strategy

### Slow Performance
- Normal in real AI mode (30-60s)
- Mock mode should be 1-2s
- Check network if using real APIs

## Next Steps

1. **Try All Task Types**
   - Refactor, debug, create, optimize, explain, architecture

2. **Test Each Merge Strategy**
   - Compare balanced vs democratic vs expert

3. **Explore Command Palette**
   - âŒ˜K for quick access to all features

4. **Review Individual Responses**
   - Learn from different AI perspectives

5. **Integrate with Real AIs**
   - Replace mock workers with real API calls
   - Maintain same interface
